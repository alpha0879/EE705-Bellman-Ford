\documentclass[12pt]{article}
\textwidth 7in
\textheight 9in
\topmargin -0.5in
\oddsidemargin -0.2in
\evensidemargin -0.2in
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{gensymb}
\usepackage{siunitx}

\title{EE705 - vlsi design lab\\ \\ \\
Course Project}
\author{ }
\date{ }

\begin{document}
\maketitle
\newpage
\begin{center}
\section*{Bellman – Ford Algorithm}
\end{center}
\subsection*{Introduction}
Reference [1] suggests an efficient implementation of Single Source Shortest Path using Bellman Ford algorithm.  Data parallelism has been exploited, to concurrently process multiple edges in each clock cycle, regardless of the data dependencies. 
			
Graphs are important to represent real world data. We use FPGA methods to solve the graph problem. On – chip memory is used in this approach, since the demonstration only uses a subset of the graph . Single-Source Shortest Path (SSSP) is a fundamental graph algorithm, which finds the shortest paths from a source vertex to all other vertices in the graph. Many applications require high speed Single Source Shortest Path computations. There are many implementations done for SSSP computations, the reference [1] uses Bellman – Ford Algorithm. It relaxes the weights of an edges in an iterative manner until shortest path to all vertices in the graph are computed. The computation complexity under the worst case is $O(v.e)$ , where v is the number of vertices and e is the number of edges. The implementation uses an early – stop logic, since in real practice the number of iterations are much less. The algorithm used by Bellman – Ford is shown in the below figure. \\
\begin{figure}[H]
\centering
\includegraphics[width=4in,height=4.5in]{1.jpg}\\
\caption{Algorithm of Bellman–Ford. (Source : [1])}
\end{figure} 
\newpage
In this implementation, a pipeline architecture is implemented which process multiple edges in parallel and mitigating the data dependency hazards by data forwarding. Also since the iteration may not happen for v*e number of times, an early termination logic is implemented. If no updates are performed during an iteration, then the computation will be immediately terminated which significantly reduces the run time .

\subsection*{Implementation}

\subsubsection*{Stage I - Memory Read Edges }\\ \\
We use a graph of 23 vertices, and 31 edges which is stored in on chip memory in FPGA. 4 memory words for p edges are streamed every clock cycle from the on-chip ROM in Memory Read Edge stage which is the first stage in the pipelined architecture as shown in the figure below. \\ \\

\begin{figure}[h]
\centering
\includegraphics[width=6.5in,height=3in]{stages.jpg}\\
\caption{Implementation of Pipelined Bellman – Ford Algorithm.}
\end{figure}

\subsubsection*{Stage II - Sorting Block }\\ \\
The input to the sorting block is 4 memory words, each memory word has the weight of the source vertex ( w(i) ), the weight of the edge between source vertex and destination vertex ( w(i, j) ) and the indices i and j. These 4 words are sorted in the sorting block to ensure that each destination index of 4 edges will have only one valid update.  There are chances that more than one edges target the same destination vertex but produce different update values. For example, memory word $< w(10, 2) = 8, w(10) = 3 >$ and memory word with $< w(6,2) = 2, w(6) = 4 >$ both target vertex 2, but the possible update values for vertex 2 based on them are 11 and 6, respectively. For each destination vertex, only the minimum update value should be considered (6 in this example). The sorting block is used to identify the possible minimum update value for each destination vertex.  \\ \\

A 1 bit update signal indicates whether the target to be updated is valid or not. Initially the update of all words are set to 1 which indicates all the updates are valid. Each comparator then checks the update signals of 4 memory words. If both the update signals are 1 and the destination vertex is same, then the comparator compares the update values w(i, j)+w(i), and it sets the update value as 0 for the memory word with a larger value. Hence after the sorting block, even if multiple memory words point to same destination vertex, each destination vertex will only have 1 valid update. \\ 
\begin{figure}[h]
\centering
\includegraphics[width=4in,height=3in]{2.jpg}
\caption{Sorting Block. (Source : [1])}
\end{figure}

Thus each of the 4 memory words from the output of sorting block will have  update signal which indicates whether the target to be updated is valid, w(i) ,the weight of the source vertex , w(i,j) the weight of the edge between vertices i and j and the indices i and j. This is passed on to Memory Read Vertex Stage. \\
 \subsubsection*{Stage III - Memory Read Vertex}
The Read Vertex Stage fetches w(j), the weight of the destination vertex from the ROM. Finally the output of Read Vertex stage that is passed on to computation block will be the vector  ${ update, w(i,j), i , j, w(i), w(j) }$ for each memory word.

\newpage
 \subsubsection*{Stage IV - Computation Block}
 \begin{figure}[h]
\centering
\includegraphics[width=3in,height=3in]{3.jpg}\\
\caption{Computation Block. (Source : [1])}
\end{figure}

The computation block computes $w(i) + w(i, j)$ for each memory word, and the result is compared with the current w(j) using a comparator. If $w(j) < w(i) + w(i, j)$ and the corresponding update signal from the previous stage is 1, then the final update signal is set as 1, otherwise it is kept as 0. Each comparison module as highlighted is responsible for 1 memory word. 

\subsubsection*{Stage V - Memory Write Stage}
The memory write stage updates $w(j)$ for each memory word, whose final update signal is set as 1. \\

If there is no valid update for consecutive iterations, an early stop logic detects this and terminates the computation. Hence as soon as the weights of all vertex converges, the iteration is stopped which helps in significantly reducing the computation time. \\

\subsubsection*{Data Forwarding}
Data hazard can occur when the same vertex is updated in two consecutive clock cycles. This may result in increasing the weight of vertex.  In the figure shown below [1] , the values in the latter clock cycle has $<w(8,6) = 6, w(8) = 11>$ and w(6) = 20  while the values in the former clock cycle has $<w(10,6) = 3, w(10) = 12 >$and w(6) = 20 in the computation block.  The output of computation block will update w(6) to 15, however the value of w(6) in the computation block will still be 20. Thus at the latter clock, the value of w(6) will be over-written as 17 and results in a hazard. \\

 \begin{figure}[H]
\centering
\includegraphics[width=4in,height=3in]{4.jpg}\\
\caption{Example of Data Hazard. (Source : [1])}
\end{figure}

\\Rather than stalling the pipeline which affects the throughput, data forwarding is implemented to mitigate these hazards as shown in figure below. The output from Write Back stage is forwarded to Computation Block Stage and Memory Read Vertex stage as shown in the figure below [1]. 
\begin{figure}[H]
\centering
\includegraphics[width=4in,height=3in]{5.jpg}\\
\caption{Implementation of Data Forwarding. (Source : [1])}
\end{figure}

\newpage
\subsection*{Detailed Pipelined Architecture}

 \begin{figure}[H]
\centering
\includegraphics[width=7in,height=4in]{pipelinedarch.png}\\
\caption{Detailed pipelined architecture}
\end{figure}

The number of bits taken for the respective elements is tabulated as shown below \\ \\

\begin{table}[h!]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5} 
 \begin{tabular}{| c | c | c |} 
 \hline
  Element & Notation & No. of bits \\
 \hline
 Weight of edge between vertices i and j & w(i,j) & 4  \\ 
 \hline
Weight of vertex i or j & w(i) or w(j) & 7\\
\hline
Vertex index i or j & i or j & 5 \\
\hline
Update signal & UP & 1 \\
\hline

 \end{tabular}
\end{table}
\\ \\
\newpage
The format in which the combination of above elements stored in ROM and Reg File is as follows. \\

\begin{table}[h!]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5} 
 \begin{tabular}{| c | c | c | c | c | c | c |} 
 \hline
   Parameter & \multicolumn{6}{|c|}{Format} \\
 \hline
 One row in ROM & \multicolumn{4}{|c|}{w(i, j)} & i & j  \\
 \hline
One row in Reg File & \multicolumn{3}{|c|}{w(i)} & \multicolumn{3}{|c|}{predecessor}\\
\hline
Input to Sorting Block & \multicolumn{3}{|c|}{w(i, j)} & i & j & w(i) \\
\hline
Output to Sorting Block & UP & \multicolumn{2}{|c|}{w(i, j)} & i & j & w(i) \\
\hline
Input to computational block & UP & w(i, j) & i & j & w(i) & w(j) \\
\hline
 \end{tabular}
\end{table}

\subsection*{ Sample Graph and Expected Results}
 \begin{figure}[H]
\centering
\includegraphics[width=4in,height=3in]{6.jpg}\\
\caption{Sample graph with bellman ford algorithm solution (Source : [2])}
\end{figure}


A graph has been plotted using [2] for verification purpose. The graph consists of a total 23 nodes and 31 edges. The number marked in brown denote the node number and number adjacent to arrows denote edge weights. The value inside the circle denote the final weights of respective nodes upon completion of Bellman Ford algorithm. Upon giving the source node as 1, the lines in green denote the shortest path to respective nodes. \\ 

\newpage
\subsection*{ Simulation Results from ModelSim}

A testbench has been created for pipelined Bellman Ford algorithm verification. Upon on simulation on Model Sim, the following results were obtained. \\ 
  \begin{figure}[H]
\centering
\includegraphics[width=2in,height=4in]{7-source1_rom_table.JPG}\\
\caption{Memory List state of Reg File upon completion of Bellman Ford algorithm}
\end{figure}


For evaluation purpose let's take destination node as 7. \\

\begin{table}[h!]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.25} 
 \begin{tabular}{| c | c | c | c |} 
 \hline
  Node & Content of Reg File & Final wt. of node (7 bit MSB) & Predecessor Addr ( 5 Bit LSB )  \\
 \hline
00000007 & 000100000100 & 0001000 (8) & 00110 (6) \\ 
 \hline
00000006 & 000011100011 & 0000111 (7) & 00011 (3) \\ 
\hline
00000003 & 000010000001 & 0000100 (4) & 00001 (1) \\ 
\hline
 \end{tabular}
\end{table}
\\ \\
The observed result in simulation is same as that obtained from [2]. Similarly several destination nodes were checked and verified. \\

\subsection*{Timing Analysis}

\begin{table}[H]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5} 
 \begin{tabular}{| c | c | c | c |} 
 \hline
  Model and Clock Period & Setup Slack & Hold Slack & fmax  \\
 \hline
Low 1200 mV 85C Model and 16 ns & 0.550 ns & 0.356 ns & 64.72 MHz \\ 
 \hline
 \end{tabular}
\end{table}
\\ \\
  \begin{figure}[H]
\centering
\includegraphics[width=4in,height=2in]{fmax.jpg}\\
\caption{fmax summary}
\end{figure}

  \begin{figure}[H]
\centering
\includegraphics[width=6in,height=3in]{setup_summary.jpg}\\
\caption{Setup Time Summary}
\end{figure}

  \begin{figure}[H]
\centering
\includegraphics[width=6in,height=3in]{Hold_summary.JPG}\\
\caption{Hold Time Summary}
\end{figure}




\end{document}